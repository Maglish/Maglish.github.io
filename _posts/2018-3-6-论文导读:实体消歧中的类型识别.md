---
layout:     post
title:      实体消岐中的类型识别
# subtitle:   
date:       2018-3-8
author:     yihao
header-img: img/2017-11-6-header.png
catalog: true
category: public 
tags:
    - Deep Learning
    - Natural Language Processing
---


# 实体消岐中的类型识别

本文使用一种神经网络自决策的方法，判断一个词是否属于100个自动发现的类型，从而确定单词的实体对象。例如，对于一句话“the prey saw the jaguar cross the jungle”，不同于以往的直接推断“jaguar”是车、动物还是其他东西，该系统会用“20个问题”来分析jaguar究竟属于哪个预选类别。这种方法相较于几个实体消歧(Entity Disambiguation)数据集上的最好方法有显著的提升。
论文原文地址：[DeepType: Multilingual Entity Linking by Neural Type System Evolution](https://arxiv.org/abs/1802.01021)
Github项目地址：https://github.com/openai/deeptype

![img1](https://i.imgur.com/QxgHb6m.png)
![img2](https://i.imgur.com/C6N2BqF.png)

上图是对该类型系统的一个简单说明。在训练数据中jaguar被认为是捷豹汽车的概率是70%，被认为是美洲豹的概率是29%，被认为是豹式飞机的概率是1%。使用我们的“类型”方法进行判断，对第一个例子中的消岐效果影响不大，因为模型认为美洲豹沿着高速公路奔跑的情况是可能存在的，但是在第二个例子中，模型认为捷豹汽车穿越丛林这件事显然是不太可能出现的。

我们在[CoNLL(YAGO)](https://www.mpi-inf.mpg.de/departments/databases-and-information-systems/research/yago-naga/aida/)取得了94.88%的准确率，之前最好的准确率是91.50%和91.70%。并在TAC KBP 2010挑战赛上取得了90.85%的准确率，而之前的最好的准确率是87.20%和87.70%。之前的方法均使用了词向量的方法，但是对于实体消歧这类任务，基于类型的方法往往能够更好的胜出，因为完美的“类型”预测可以得到98.6%至99%的准确率。

## 整体框架

我们的系统分为下面几个步骤：

1. **提取每个单词的维基百科内部链接,以确定每个单词可供参考的实体集合**。例如，当我们在维基百科的页面遇到链接\[jaguar](https://en.wikipedia.org/wiki/Jaguar)时,我们就认为链接`https://en.wikipedia.org/wiki/Jaguar`可能是jaguar的一个含义。
1. **通过对维基百科类别树的遍历(使用[Wikidata](https://www.wikidata.org/wiki/Wikidata:Introduction)知识图)来决定每个实体所属的类别集合。**比如说，在页面`https://en.wikipedia.org/wiki/Jaguar_Cars’s`的底部，是下表中的这些类(它们都有其专属类别，比如[Automobiles](https://en.wikipedia.org/wiki/Category:Automobiles))：
[Categories: [British barnds] [Car brands] [Jaguar Car] [Jaguar vechicles]](https://en.wikipedia.org/wiki/Jaguar_Cars#mw-normal-catlinks)
1. **选择一个含有100种类别的列表当作你的类型系统，然后优化该系统，使选取的类别可以更紧凑的表示任何实体。**这样我们就知道了实体到类别的映射关系，所以对于我们的类型系统，可以将每个类别中的每个实体表示为约100维的唯一的二值向量，这个向量表示了该实体与每个类别的从属关系。
1. **使用每个维基百科的内部链接以及其上下文来产生训练数据，我们需要使用神经网络来学习一种映射关系，即单词到100维的二值向量之间的映射。**这一步将之前的步骤联系起来：维基百科的链接将单词与实体相连，通过第二步我们知道了每一个实体的类别，而第三步则在我们的类型系统中选择了实体所属的类别。
1. **在测试阶段，给定一个词语以及其上下文，我们的神经网络将输出该词语属于其类型系统中每一个类别的概率。**如果我们知道了类别成员的准确集合，我们可以将结果缩小到一个实体(假设分类结果是完美的)。但实际上，我们必须计算大概20个概率问题：对于该单词的每一个可能对应的实体，都需要使用[贝叶斯理论](https://en.wikipedia.org/wiki/Bayes%27_theorem)来计算其概率。
## 更多的例子
下面是类型系统的一些实例，更多内容请点击原文查看：
![img1](https://i.imgur.com/S8esX3S.png)

![img4](https://i.imgur.com/DBEAkQK.png)
## 清洗数据
Wikidata的知识图可以转化为训练数据源，完成细粒度实体到类型的映射。对于给定的实体，我们使用它的[实体(instance of )](https://www.wikidata.org/wiki/Property:P31) 递归关系来决定其类型集，比如说，[huamn](https://www.wikidata.org/wiki/Q5)节点的子节点中有human这个类型。维基百科通过其类别链接也会提供一种实体到类别的映射。

对于一些实体，维基百科内部链接的统计可以提供一个比较好的相关短语。然而，有些时候链接到的是具体的实例而不是类别本身，这样就会产生信息上的噪声([anaphora](https://en.wikipedia.org/wiki/Anaphora_(linguistics))--例如，国王(king)这个词就会被链接到英格兰查理一世(Charles I of England))。这种情况会导致相关实例的数量的爆炸增长与链接有效性的下降(例如，queen 被链接到了乐队[Queen(皇后乐队)](https://en.wikipedia.org/wiki/Queen_(band))4920次，[Elizabeth II(伊丽莎白二世)](https://en.wikipedia.org/wiki/Queen_(band))1430次，[monarch(君主)](https://en.wikipedia.org/wiki/Monarch)只有32次)。

最简单的方法是删除少见的链接，但是这会造成有效信息的丢失。而我们使用Wikidata属性图启发式地将链接转化为更加“通用”的含义，详细说明可以看下图。
![img1](https://i.imgur.com/sCT31Yt.png)

经过这一步的处理，king这个单词的相关实体从974降到14个，并且queen到monarch的连接数从32增加到3553。

## 选择一个好的类型系统
我们需要选择一个最好的类型系统和参数使得消岐准确率最大化。由于存在大量的可能类型集，找到一个精确解是十分困难的。因此我们使用了启发式的搜索和随机优化(进化算法)来选择类型系统，并使用梯度下降训练类型分类器来预测类型系统的表现。
![img](https://i.imgur.com/hAYoGHH.png)
> ROC曲线绘制了真阳性率(true positive)随假阳性率(false positive)增加时的变化情况，上图是一个AUC为0.76时的ROC曲线。一个随机的分类器将会得到一条直线作为其ROC曲线(图中的虚线)。

我们需要选择易于区分的类型(这样可以快速地减少可能的实体集合)，同时易于学习(即上下文可以为神经网络的类型推断提供有效的信息)。我们使用两种启发式的准则对搜索方法进行了评估与优化：可学习性与准确性。可学习性的判定准则是使用ROC曲线下的面积([AUC](http://fastml.com/what-you-wanted-to-know-about-auc/))的平均值，使用AUC训练分类器来预测类型成员。而类型预测准确率的提高可以从另一个方面说明歧义的消除。

## 类型系统评价

![img](https://i.imgur.com/obft8h8.png)

在给定的单词范围中，我们使用二分类器在数据的150,000个公共类型中对其成员做可能性预测。某个类型的分类器的AUC成为了“可学习性分数”的标志。高的AUC意味着从上下文中可以很轻松的对这一类型做预测，性能不好的分类器可能是由于对于这一类对应的训练数据不够或者因为给定的单词范围不理想(这一现象常发生在一些非自然的类中，如[ISBNs](zuohttps://en.wikipedia.org/wiki/International_Standard_Book_Number))。完整模型的训练需要耗费几天的时间，所以我们使用更小的模型作为评估“可学习性分数”的一个示例，这样只需要2.5秒就可以完成训练。

现在我们可以使用这些学习能力分数和统计数据来评估我们的类型系统中的一些子集的性能。下图是使用[交叉熵](https://en.wikipedia.org/wiki/Cross-entropy_method)进行优化的效果，点击[原文](https://blog.openai.com/discovering-types-for-entity-disambiguation)可以查看动态优化过程。
![img](https://i.imgur.com/yVDOnhU.png)

为了更好的了解在设计一个类型系统时，哪些部分比较容易哪些部分比较困难，[原文](https://blog.openai.com/discovering-types-for-entity-disambiguation/)提供了一个交互式的系统让用户可以手动训练自己的类型系统，通过选择你认为正确的连接关系，可以达到消歧的目的。
在这个系统中，你可以选择一个大类，比如下图中的Politics&Business,然后对其中有歧义的词语开始进行训练。
![img](https://i.imgur.com/RNrgfTq.png)
每个大类中的选项如下图所示，对于例句中的词语有可能的答案显示在顶端，正确的答案是有颜色的那个，底部的是一些可用的类型。连线表示的是顶部的节点与底部节点之间的继承关系，通过选择你想使用的继承关系可以对分类器进行训练。直到你所选择的继承关系数量足够将正确答案与其它选项划分出来，这时就达到了消歧的目的。
![img](https://i.imgur.com/zHPaBAC.png)


## 神经类型系统

现在我们可以使用训练好的类型系统对维基百科的数据进行标注。用这个数据(在我们的试验中，每个英文和法文都有40亿个标注样本)，我们可以训练一个双向LSTM网络来独立预测每个单词的所有类型成员。在维基百科源文本上，我们只有内部链接的监督信息，然而这些足以训练一个在F1上预测精度超过0.91的网络。

这里有一个有趣的事情，通过定向搜索发现，基本所有的类型系统都包含了Aviation、Clothing和Games这些类(这就像是`1754 in Canada`这个词条，这表明在这个数据库中，1754是一个非常令人激动的一年)，点击[这里](https://s3-us-west-2.amazonaws.com/openai-public/blog/2018-01/neural-type-system/greedy.txt)可以查看完整的类型列表。

## 分析

预测文档中的实体通常依赖于不同实体之间的“一致性”度量。例如，测量每个实体相互之间的匹配程度，其算法时间复杂度是O(N^2)。但是我们的方法时间复杂度是O(N)，因为我们只需要在树中查找每个短语，将短语映射到其可能的含义。我们根据维基百科中采集的链接频次对所有可能的实体进行排序，并使用每个实体在分类器下的似然概率对其进行加权。新的实体可以通过指定其类型成员(人、动物、原国籍、时间段等)来添加。

## 未来工作

在实体消歧的问题上，本文的方法和之前的其他方法有许多的不同点。端到端的词向量学习方法与本文讲述的基于类型推断的方法之间的性能比较，这是作者目前非常感兴趣的一点。本文提到的类型系统仅使用了维基百科的很小的子集，当然你也可以扩展到所有的维基百科数据上，以得到更广泛的应用。

查看原文:[Discovering Types for Entity Disambiguation](https://blog.openai.com/discovering-types-for-entity-disambiguation/)


